DuckDB Data Pipeline â€” Flask + Streamlit

Small end-to-end data pipeline to ingest, analyze, visualize, and persist datasets with DuckDB, Pandas, and Streamlit.
The repo also includes a (optional) Flask app.

âœ¨ Features

Upload CSV / JSON / Excel / Parquet

Quick EDA: uniques / nulls / zeros per column

Auto histograms for first numeric columns

Save to Parquet and DuckDB (outputs/output.duckdb)

Optional SQL on the in-memory DataFrame via DuckDB

Dockerized, with persistent volumes for uploads/outputs/static

ğŸ—‚ï¸ Project structure
.
â”œâ”€ app/
â”‚  â”œâ”€ logic/
â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â”œâ”€ file_loader.py      # load_file()
â”‚  â”‚  â”œâ”€ etl_utils.py        # analyze_dataframe()
â”‚  â”‚  â”œâ”€ save_utils.py       # save_parquet(), save_duckdb()
â”‚  â”‚  â””â”€ viz_utils.py        # generate_graphs()
â”‚  â”œâ”€ templates/             # Flask templates (optional)
â”‚  â””â”€ __init__.py            # Flask factory (optional)
â”œâ”€ app_streamlit.py          # Streamlit UI
â”œâ”€ run.py                    # Flask entrypoint (optional)
â”œâ”€ requirements.txt
â”œâ”€ docker-compose.yml
â”œâ”€ Dockerfile                # base image (can be used by both services)
â”œâ”€ Dockerfile.streamlit      # optional separate Dockerfile for Streamlit
â”œâ”€ uploads/                  # user uploads  (mounted volume)
â”œâ”€ outputs/                  # parquet/duckdb (mounted volume)
â””â”€ app/static/               # saved charts  (mounted volume)

ğŸš€ Quickstart (Docker)

Note: Modern Compose ignores the version: key. Remove it if you see a warning.

Streamlit only
docker compose build --no-cache
docker compose up


Open: http://localhost:8501

Streamlit + Flask (if enabled in compose)

Streamlit â†’ http://localhost:8501

Flask â†’ http://localhost:5000
